{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b3c7e9",
   "metadata": {
    "id": "07b3c7e9"
   },
   "source": [
    "# **FICO Analytic Challenge Â© Fair Isaac 2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6255ef9",
   "metadata": {
    "id": "f6255ef9"
   },
   "source": [
    "# Blind Holdout Set: Generating Features and Scores without Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NlwPPpjutipt",
   "metadata": {
    "id": "NlwPPpjutipt"
   },
   "source": [
    "## Mount the Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tZbpimXWdzI4",
   "metadata": {
    "id": "tZbpimXWdzI4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)\n",
    "\n",
    "path = '/content/drive/MyDrive/FICO Analytic Challenge/'\n",
    "sys.path.append(path +'Data')\n",
    "sys.path.append(path +'Model')\n",
    "sys.path.append(path +'Week 04')\n",
    "sys.path.append(path +'Week 06')\n",
    "sys.path.append(path +'Week 07')\n",
    "# sys.path.append(path +'Week 10')\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bcc763",
   "metadata": {
    "id": "a5bcc763"
   },
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad145907",
   "metadata": {
    "id": "ad145907"
   },
   "outputs": [],
   "source": [
    "# import the necessary libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pickle import dump, load\n",
    "from fico_functions import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "\n",
    "# Pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Removing limitation in viewing pandas columns and rows\n",
    "pd.set_option('display.max_columns', None, 'display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754e687",
   "metadata": {
    "id": "2754e687"
   },
   "outputs": [],
   "source": [
    "# Checking GPU compatibility\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91807ebc",
   "metadata": {
    "id": "91807ebc"
   },
   "outputs": [],
   "source": [
    "# path to model\n",
    "mdlPath = f\"{path}Model\"\n",
    "\n",
    "# Folder's name that's holding data of interest\n",
    "data = 'Data'\n",
    "\n",
    "# Model name; this will be used to distinguish model's output files\n",
    "model='NNet'\n",
    "\n",
    "# import scale file\n",
    "scaleFile = os.path.join(path + data, 'scaler.' + model + '.' + data + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775bcc75",
   "metadata": {
    "id": "775bcc75"
   },
   "source": [
    "### Blind Holdout Dataset\n",
    "- **test_C_**<font color='CornflowerBlue'>notags</font>**.csv** is the blind holdout dataset\n",
    "    - you should have already created the features for it and named it either of the following:\n",
    "        - **test_C_**<font color='DeepSkyBlue'>notags_features</font>**.csv**\n",
    "            - if only using features from week 4\n",
    "        - **test_C_**<font color='lightgreen'>notags_advanced_features</font>**.csv**\n",
    "            - if also using week 8\n",
    "- **score.NNet.test_C_**<font color='DeepSkyBlue'>notags_features</font>**.csv** or **score.NNet.test_C_**<font color='lightgreen'>notags_advanced_features</font>**.csv**\n",
    "    - this should have scores from your trained NNet model\n",
    "    - this dataset doesn't have the following columns since it has \"<font color='CornflowerBlue'>**notags**</font>\"\n",
    "        - mdlIsFraudTrx\n",
    "        - mdlIsFraudAcct\n",
    "- <font color='Cyan'>**score.NNet.test_C_features.csv**</font> or <font color='MediumPurple'>**score.NNet.test_C_advanced_features.csv**</font>\n",
    "    - this is the file's name that we'll return to you which includes the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xlAKLK6hZk8d",
   "metadata": {
    "id": "xlAKLK6hZk8d"
   },
   "outputs": [],
   "source": [
    "# def get_blindholdout_file(path, data, model, blindholdoutFile, featureTestFileSuffix):\n",
    "#   # Blind Holdout file location\n",
    "#   blindholdoutCSV = os.path.join(path + data, blindholdoutFile[0] + featureTestFileSuffix)\n",
    "\n",
    "#   if not os.path.isfile(blindholdoutCSV):\n",
    "#       featureTestFileSuffix=\"_features.csv\"\n",
    "#       blindholdoutCSV = os.path.join(path + data, blindholdoutFile[0] + featureTestFileSuffix)\n",
    "\n",
    "#       if not os.path.isfile(blindholdoutCSV):\n",
    "#           raise FileNotFoundError(f\"{blindholdoutCSV} does not exist in {path}{data} directory\")\n",
    "\n",
    "#       return blindholdoutCSV, featureTestFileSuffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4fd75",
   "metadata": {
    "id": "c8c4fd75"
   },
   "outputs": [],
   "source": [
    "# def get_feature_cols(df1, blindholdoutFile):\n",
    "#     base_columns = ['pan', 'merchant', 'category', 'transactionAmount', 'first', 'last', 'mdlIsFraudTrx', 'mdlIsFraudAcct',\n",
    "#                 'is_train', 'cardholderCountry', 'cardholderState', 'transactionDateTime', 'gender',\n",
    "#                 'street', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time',\n",
    "#                 'merch_lat', 'merch_long', 'merchCountry', 'merchState', 'deltaTime', 'y_preds', 'score']\n",
    "\n",
    "#     blind = False\n",
    "#     del_cols = []\n",
    "#     for col in base_columns:\n",
    "#         if col not in df1.columns:\n",
    "#             del_cols.append(col)\n",
    "#             # base_cols.remove(col)\n",
    "#             if col == 'mdlIsFraudTrx':\n",
    "#                 blind = True\n",
    "\n",
    "#     base_cols = list(set(base_columns) - set(del_cols))\n",
    "#     feature_columns = list(set(df1.columns) - set(base_cols))\n",
    "#     feature_columns.sort()\n",
    "\n",
    "#     print(f'\\033[1mColumns in\\033[0m: {blindholdoutFile}')\n",
    "#     print(f\"Number of Columns in Base: {len(base_cols)}\")\n",
    "#     print(f\"Base Columns: {base_cols}\")\n",
    "#     print(f\"Number of Features: {len(feature_columns)}\")\n",
    "#     print(f\"Input Features: {feature_columns}\")\n",
    "\n",
    "#     if not blind:\n",
    "#         label_column = [\"mdlIsFraudTrx\"]\n",
    "#         print(f\"Label Column: {label_column}\\n\")\n",
    "#         return feature_columns, label_column, base_cols\n",
    "#     else:\n",
    "#         label_column = [\"\"]\n",
    "#         return feature_columns, label_column, base_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b49662",
   "metadata": {
    "id": "01b49662"
   },
   "outputs": [],
   "source": [
    "# Change to correct file name\n",
    "blindholdoutFile = ['test_C_notags']\n",
    "# CSV filename suffex\n",
    "featureTestFileSuffix=\"_advanced_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quVYQrqvK3Uy",
   "metadata": {
    "id": "quVYQrqvK3Uy"
   },
   "outputs": [],
   "source": [
    "blindholdoutCSV, featureTestFileSuffix = get_blindholdout_file(path, data, model, blindholdoutFile, featureTestFileSuffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hSSCJz3Se_5T",
   "metadata": {
    "id": "hSSCJz3Se_5T"
   },
   "outputs": [],
   "source": [
    "# Holdout file save directory\n",
    "blindholdoutsaveCSV = os.path.join(path + data, 'score.' + model + '.' + blindholdoutFile[0] + featureTestFileSuffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f717855",
   "metadata": {
    "id": "3f717855"
   },
   "outputs": [],
   "source": [
    "# test dataset\n",
    "df_test = import_df(blindholdoutCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089cf13",
   "metadata": {
    "id": "d089cf13"
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k_KpKiDuy6Ge",
   "metadata": {
    "id": "k_KpKiDuy6Ge"
   },
   "source": [
    "### Lists Containing Names of Input Features and Label Columns <font color='red'>(**Modify base_cols to match your dataset's columns that aren't features**)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bETqQ5m8luAq",
   "metadata": {
    "id": "bETqQ5m8luAq"
   },
   "outputs": [],
   "source": [
    "len(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dZEuen4LT1m",
   "metadata": {
    "id": "1dZEuen4LT1m"
   },
   "outputs": [],
   "source": [
    "feature_columns, label_column, base_cols = get_feature_cols(df_test, blindholdoutFile[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qrQnPRzxdwHG",
   "metadata": {
    "id": "qrQnPRzxdwHG"
   },
   "outputs": [],
   "source": [
    "# Features to save\n",
    "saveFeatures_blind = [*base_cols, *feature_columns, 'y_preds', 'score']\n",
    "print(f\"Features to save: {saveFeatures_blind}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kxGW0dxLdwEz",
   "metadata": {
    "id": "kxGW0dxLdwEz"
   },
   "outputs": [],
   "source": [
    "#hyper-parameters\n",
    "dropout_rate = 0.2\n",
    "num_hidden_units = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350r_NedwAM",
   "metadata": {
    "id": "e350r_NedwAM"
   },
   "outputs": [],
   "source": [
    "# Import best LAUC Model\n",
    "laucModel = os.path.join(mdlPath, \"model_best_valid_lauc.\"+str(num_hidden_units)+\"nodes.\"+ data +\".pt\")\n",
    "model_l_NNet = NNet(input_size=len(feature_columns), hidden_units=num_hidden_units, output_size=1, dropout=dropout_rate)\n",
    "model_l_NNet.load_state_dict(torch.load(laucModel))\n",
    "model_l_NNet.to(device)\n",
    "model_l_NNet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ph-ZSUBLdqFs",
   "metadata": {
    "id": "ph-ZSUBLdqFs"
   },
   "outputs": [],
   "source": [
    "df_blind_holdout = blind_holdout_score_NNet(blindholdoutCSV, scaleFile, feature_columns, device, model_l_NNet, saveFeatures_blind, blindholdoutsaveCSV)\n",
    "df_blind_holdout.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
